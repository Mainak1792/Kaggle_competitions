{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "food101.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYjmxjDK6dQG"
      },
      "source": [
        "Unpack food 101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T78-XdOhEkf2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0oYSv3N6S-Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "e2c997b7-2283-4c74-a805-fc3be7c96be8"
      },
      "source": [
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/MyDrive/food101/food-101.zip\", outdir=\"/content/drive/MyDrive/food101\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 28.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.9MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "patool: Extracting /content/drive/MyDrive/food101/food-101.zip ...\n",
            "patool: running /usr/bin/7z x -o/content/drive/MyDrive/food101 -- /content/drive/MyDrive/food101/food-101.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "PatoolError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPatoolError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-74839504d957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install patool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatoolib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpatoolib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/food101/food-101.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/food101\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/patoolib/__init__.py\u001b[0m in \u001b[0;36mextract_archive\u001b[0;34m(archive, verbosity, outdir, program, interactive)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbosity\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting %s ...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/patoolib/__init__.py\u001b[0m in \u001b[0;36m_extract_archive\u001b[0;34m(archive, verbosity, interactive, outdir, program, format, compression)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# already handled the command (eg. when it's a builtin Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;31m# function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mrun_archive_cmdlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_cleanup_outdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanup_outdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/patoolib/__init__.py\u001b[0m in \u001b[0;36mrun_archive_cmdlist\u001b[0;34m(archive_cmdlist, verbosity)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mcmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_cmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_checked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrunkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/patoolib/util.py\u001b[0m in \u001b[0;36mrun_checked\u001b[0;34m(cmd, ret_ok, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Command `%s' returned non-zero exit status %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPatoolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPatoolError\u001b[0m: Command `['/usr/bin/7z', 'x', '-o/content/drive/MyDrive/food101', '--', '/content/drive/MyDrive/food101/food-101.zip']' returned non-zero exit status 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoIYFBae8EFX"
      },
      "source": [
        "Visualise Random Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STVID9e08GL8"
      },
      "source": [
        "# Visualize the data, showing one image per class from 101 classes\n",
        "rows = 17\n",
        "cols = 6\n",
        "fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n",
        "fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n",
        "data_dir = \"/content/drive/MyDrive/food101/food-101/images\"\n",
        "foods_sorted = sorted(os.listdir(data_dir))\n",
        "food_id = 0\n",
        "for i in range(rows):\n",
        "  for j in range(cols):\n",
        "    try:\n",
        "      food_selected = foods_sorted[food_id] \n",
        "      food_id += 1\n",
        "    except:\n",
        "      break\n",
        "    if food_selected == '.DS_Store':\n",
        "        continue\n",
        "    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n",
        "    food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n",
        "    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n",
        "    ax[i][j].imshow(img)\n",
        "    ax[i][j].set_title(food_selected, pad = 10)\n",
        "    \n",
        "plt.setp(ax, xticks=[],yticks=[])\n",
        "plt.tight_layout()\n",
        "# https://matplotlib.org/users/tight_layout_guide.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R_Q2Zt-8J3l"
      },
      "source": [
        "Train_Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KLyUkr4E6tl"
      },
      "source": [
        "os.listdir('/content/drive/MyDrive/food101/food-101/meta')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm6Fe7OLE_fv"
      },
      "source": [
        "!head /content/drive/MyDrive/food101/food-101/meta/train.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4b4GiPNFXYE"
      },
      "source": [
        "# Helper method to split dataset into train and test folders\n",
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceyaL3idFaJU"
      },
      "source": [
        "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
        "%cd /\n",
        "print(\"Creating train data...\")\n",
        "prepare_data('/content/drive/MyDrive/food101/food-101/meta/train.txt', '/content/drive/MyDrive/food101/food-101/images', 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L7C4y06ICtO"
      },
      "source": [
        "# Check how many files are in the train folder\n",
        "print(\"Total number of samples in train folder\")\n",
        "!find train -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnMF9cQbIJF2"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmmZg7qGIKEz"
      },
      "source": [
        "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
        "print(\"Creating test data...\")\n",
        "prepare_data('/content/drive/MyDrive/food101/food-101/meta/test.txt', '/content/drive/MyDrive/food101/food-101/images', 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oholoOmRJLaX"
      },
      "source": [
        "# Check how many files are in the test folder\n",
        "print(\"Total number of samples in test folder\")\n",
        "!find test -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgMV30yXJX0O"
      },
      "source": [
        "# List of all 101 types of foods(sorted alphabetically)\n",
        "del foods_sorted[0] \n",
        "foods_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAYXoAkzwtJv"
      },
      "source": [
        "base = MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
        "base.trainable = True\n",
        "model = Sequential()\n",
        "model.add(base)\n",
        "# model.add(Flatten())\n",
        "model.add(GlobalAveragePooling2D())\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "# opt = SGD(lr=0.001, momentum=0.9)\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt,loss = 'categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFsnYIyjNRR0"
      },
      "source": [
        "K.clear_session()\n",
        "n_classes = 101\n",
        "img_width, img_height = 224, 224\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'test'\n",
        "nb_train_samples = 75750\n",
        "nb_validation_samples = 25250\n",
        "batch_size = 64\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "    # rescale=1. / 255,\n",
        "    # shear_range=0.2,\n",
        "    # zoom_range=0.2,\n",
        "    # horizontal_flip=True)\n",
        "train_datagen= ImageDataGenerator(rescale=1. / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "resnet = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(resnet.output)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "#  x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
        "\n",
        "# inception = InceptionV3(weights='imagenet', include_top=False)\n",
        "# x = inception.output\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# x = Dense(128,activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "predictions = Dense(101,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=resnet.input, outputs=predictions)\n",
        "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath='best_model_3class.hdf5', verbose=1, save_best_only=True)\n",
        "csv_logger = CSVLogger('history_3class.log')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch = nb_train_samples // batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=nb_validation_samples // batch_size,\n",
        "                    epochs=30,\n",
        "                    verbose=1)\n",
        "\n",
        "# model.save('model_trained_3class.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU2gyivH3jYL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.models as models\n",
        "mobilenet_v2 = models.mobilenet_v2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5kFCRzj3z_T"
      },
      "source": [
        "!git clone https://gist.github.com/f7b7c7758a46da49f84bc68b47997d69.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr7Yn24f31M-"
      },
      "source": [
        "!bash pytorch041_cuda92_colab.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLXHInmy3_jo"
      },
      "source": [
        "# NVIDIA profiling tool for the available GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Js0jR1C4J06"
      },
      "source": [
        "#  CLone my repo that contains the shell file\n",
        "!git clone https://gist.github.com/f7b7c7758a46da49f84bc68b47997d69.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v3Hf0so4X4X"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SqB4V-k4cXw"
      },
      "source": [
        "\n",
        "!dpkg --install cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arh1PVuU4gyH"
      },
      "source": [
        "\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udrTYrp64kMh"
      },
      "source": [
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcgSXKKy4nzj"
      },
      "source": [
        "\n",
        "# NOTE: This might take some time..\n",
        "!apt-get install cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVUkZxRF4pO1"
      },
      "source": [
        "\n",
        "# Check the version of CUDA on the system\n",
        "!cat /usr/local/cuda/version.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un2KEz8c4ziJ"
      },
      "source": [
        "\n",
        "!pip install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fERr-bhQ428X"
      },
      "source": [
        "\n",
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZC7LH2u2MRm"
      },
      "source": [
        "train_transforms = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1),\n",
        "        torchvision.transforms.RandomAffine(15),\n",
        "        torchvision.transforms.Resize((224,224)),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "valid_transforms = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize((224,224)),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B0MJ4EA2SX-"
      },
      "source": [
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'test'\n",
        "train_dataset = torchvision.datasets.ImageFolder(train_data_dir,transform=train_transforms)\n",
        "valid_dataset = torchvision.datasets.ImageFolder(validation_data_dir,transform=valid_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLR2zwFK2gEW"
      },
      "source": [
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size,shuffle=True,num_workers=4,pin_memory=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size,shuffle=False,num_workers=4,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm33VWGI2nxi"
      },
      "source": [
        "model = models.mobilenet_v2()\n",
        "for i,param in enumerate(model.parameters()):\n",
        "    if i<100:\n",
        "        param.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEgOQgHD2tg2"
      },
      "source": [
        "model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(2048,101)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IWHM3B0i5t3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TPODtcf2vbA"
      },
      "source": [
        "from torch_lr_finder import LRFinder\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(train_loader, end_lr=0.01, num_iter=10)\n",
        "lr_finder.plot()\n",
        "lr_finder.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8ucVRvk2w3W"
      },
      "source": [
        "cuda = True\n",
        "epochs = 10\n",
        "# model_name = '/content/drive/My Drive/resnet50.pt'\n",
        "model_name = '/content/drive/MyDrive/mobile_net.pt'\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=4e-5,weight_decay=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.1,patience=1,verbose=True)\n",
        "\n",
        "writer = SummaryWriter() # For Tensorboard\n",
        "early_stop_count=0\n",
        "ES_patience=5\n",
        "best = 0.0\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    # Training\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    train_loss = 0.0\n",
        "    tbar = tqdm(train_loader, desc = 'Training', position=0, leave=True)\n",
        "    for i,(inp,lbl) in enumerate(tbar):\n",
        "        optimizer.zero_grad()\n",
        "        if cuda:\n",
        "            inp,lbl = inp.cuda(),lbl.cuda()\n",
        "        out = model(inp)\n",
        "        loss = criterion(out,lbl)\n",
        "        train_loss += loss\n",
        "        out = out.argmax(dim=1)\n",
        "        correct += (out == lbl).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        tbar.set_description(f\"Epoch: {epoch+1}, loss: {loss.item():.5f}, acc: {100.0*correct/((i+1)*train_loader.batch_size):.4f}%\")\n",
        "    train_acc = 100.0*correct/len(train_loader.dataset)\n",
        "    train_loss /= (len(train_loader.dataset)/batch_size)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        val_loss = 0.0\n",
        "        vbar = tqdm(valid_loader, desc = 'Validation', position=0, leave=True)\n",
        "        for i,(inp,lbl) in enumerate(vbar):\n",
        "            if cuda:\n",
        "                inp,lbl = inp.cuda(),lbl.cuda()\n",
        "            out = model(inp)\n",
        "            val_loss += criterion(out,lbl)\n",
        "            out = out.argmax(dim=1)\n",
        "            correct += (out == lbl).sum().item()\n",
        "        val_acc = 100.0*correct/len(valid_loader.dataset)\n",
        "        val_loss /= (len(valid_loader.dataset)/batch_size)\n",
        "    print(f'\\nEpoch: {epoch+1}/{epochs}')\n",
        "    print(f'Train loss: {train_loss}, Train Accuracy: {train_acc}')\n",
        "    print(f'Validation loss: {val_loss}, Validation Accuracy: {val_acc}\\n')\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # write to tensorboard\n",
        "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
        "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
        "    writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
        "    writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
        "\n",
        "    if val_acc>best:\n",
        "        best=val_acc\n",
        "        torch.save(model,model_name)\n",
        "        early_stop_count=0\n",
        "        print('Accuracy Improved, model saved.\\n')\n",
        "    else:\n",
        "        early_stop_count+=1\n",
        "\n",
        "    if early_stop_count==ES_patience:\n",
        "        print('Early Stopping Initiated...')\n",
        "        print(f'Best Accuracy achieved: {best:.2f}% at epoch:{epoch-ES_patience}')\n",
        "        print(f'Model saved as {model_name}')\n",
        "        break\n",
        "    writer.flush()\n",
        "# writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}